{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:30.586973Z\",\"iopub.execute_input\":\"2023-08-13T12:59:30.587447Z\",\"iopub.status.idle\":\"2023-08-13T12:59:30.643427Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:30.587414Z\",\"shell.execute_reply\":\"2023-08-13T12:59:30.642403Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:31.399659Z\",\"iopub.execute_input\":\"2023-08-13T12:59:31.400494Z\",\"iopub.status.idle\":\"2023-08-13T12:59:32.250744Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:31.400457Z\",\"shell.execute_reply\":\"2023-08-13T12:59:32.249650Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nresume_df = pd.read_csv(\"/kaggle/input/resume-dataset/Resume/Resume.csv\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:32.252506Z\",\"iopub.execute_input\":\"2023-08-13T12:59:32.253796Z\",\"iopub.status.idle\":\"2023-08-13T12:59:32.267446Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:32.253758Z\",\"shell.execute_reply\":\"2023-08-13T12:59:32.266333Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nresume_df.head(5)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:32.823934Z\",\"iopub.execute_input\":\"2023-08-13T12:59:32.824370Z\",\"iopub.status.idle\":\"2023-08-13T12:59:32.842748Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:32.824337Z\",\"shell.execute_reply\":\"2023-08-13T12:59:32.841615Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nresume_df.info()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:33.612698Z\",\"iopub.execute_input\":\"2023-08-13T12:59:33.613431Z\",\"iopub.status.idle\":\"2023-08-13T12:59:33.645056Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:33.613394Z\",\"shell.execute_reply\":\"2023-08-13T12:59:33.643947Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nresume_df[\"all_text\"] = resume_df[\"Resume_str\"] + \" \" + resume_df[\"Resume_html\"]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:34.213327Z\",\"iopub.execute_input\":\"2023-08-13T12:59:34.213707Z\",\"iopub.status.idle\":\"2023-08-13T12:59:34.222704Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:34.213678Z\",\"shell.execute_reply\":\"2023-08-13T12:59:34.221214Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nlen(resume_df[\"Category\"].unique())\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:34.921867Z\",\"iopub.execute_input\":\"2023-08-13T12:59:34.922337Z\",\"iopub.status.idle\":\"2023-08-13T12:59:34.930391Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:34.922302Z\",\"shell.execute_reply\":\"2023-08-13T12:59:34.929107Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nresume_df.shape\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T12:59:36.506610Z\",\"iopub.execute_input\":\"2023-08-13T12:59:36.507005Z\",\"iopub.status.idle\":\"2023-08-13T18:07:46.905723Z\",\"shell.execute_reply.started\":\"2023-08-13T12:59:36.506975Z\",\"shell.execute_reply\":\"2023-08-13T18:07:46.901572Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom sklearn.model_selection import train_test_split\n\ndf = resume_df\n\n# Split the DataFrame into training and testing sets\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# Load the pre-trained BERT tokenizer and model\nmodel_name = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)\nnum_labels = len(df['Category'].unique())\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n\n# Define batch size and number of epochs\nbatch_size = 20\nnum_epochs = 3\n\n# Train the BERT model in batches\nfor epoch in range(num_epochs):\n    for batch_start in range(0, len(train_df), batch_size):\n        batch_end = min(batch_start + batch_size, len(train_df))\n        batch_df = train_df.iloc[batch_start:batch_end]\n        \n        batch_texts = batch_df['Resume_str'].tolist()\n        batch_labels = batch_df['Category'].tolist()\n        \n        # Tokenize the text data and features\n        batch_inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n        \n        # Convert labels to numerical format\n        label_mapping = {label: index for index, label in enumerate(df['Category'].unique())}\n        batch_labels_tensor = torch.tensor([label_mapping[label] for label in batch_labels], dtype=torch.long)\n        \n        # Train the model\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n        loss_fn = torch.nn.CrossEntropyLoss()\n        \n        model.train()\n        optimizer.zero_grad()\n        outputs = model(**batch_inputs, labels=batch_labels_tensor)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        print(\">\", end=\" \")\n    print(f\"Epoch {epoch+1}, Batch {batch_start//batch_size + 1}, Loss: {loss.item()}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:12:11.035671Z\",\"iopub.execute_input\":\"2023-08-13T18:12:11.036422Z\",\"iopub.status.idle\":\"2023-08-13T18:12:11.772603Z\",\"shell.execute_reply.started\":\"2023-08-13T18:12:11.036300Z\",\"shell.execute_reply\":\"2023-08-13T18:12:11.771363Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nfrom transformers import BertModel, BertTokenizer\n\n# Save the model and tokenizer\noutput_dir = \"bert_saved_model_1\"\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:12:20.702741Z\",\"iopub.execute_input\":\"2023-08-13T18:12:20.703900Z\",\"iopub.status.idle\":\"2023-08-13T18:20:08.693230Z\",\"shell.execute_reply.started\":\"2023-08-13T18:12:20.703847Z\",\"shell.execute_reply\":\"2023-08-13T18:20:08.690320Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport pandas as pd\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm  # For progress bar\n\n\n\n# Define batch size\nbatch_size = 8\n\n# Tokenize and evaluate the test dataset in batches\nall_predicted_labels = []\nall_true_labels = []\n\nfor batch_start in tqdm(range(0, len(test_df), batch_size)):\n    batch_end = min(batch_start + batch_size, len(test_df))\n    batch_df = test_df.iloc[batch_start:batch_end]\n    \n    batch_texts = batch_df['Resume_str'].tolist()\n    batch_labels = batch_df['Category'].tolist()\n    \n    # Tokenize the text data\n    batch_inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n    \n    # Convert labels to numerical format\n    label_mapping = {label: index for index, label in enumerate(test_df['Category'].unique())}\n    batch_labels_tensor = torch.tensor([label_mapping[label] for label in batch_labels], dtype=torch.long)\n    \n    model.eval()\n    with torch.no_grad():\n        batch_outputs = model(**batch_inputs)\n        batch_predicted_labels = torch.argmax(batch_outputs.logits, dim=1)\n    \n    all_predicted_labels.extend(batch_predicted_labels.cpu().numpy())\n    all_true_labels.extend(batch_labels_tensor.cpu().numpy())\n\n# Calculate accuracy\naccuracy = accuracy_score(all_true_labels, all_predicted_labels)\nprint(f\"Accuracy on test dataset: {accuracy:.2f}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:30.048779Z\",\"iopub.execute_input\":\"2023-08-13T18:20:30.049443Z\",\"iopub.status.idle\":\"2023-08-13T18:20:30.062811Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:30.049341Z\",\"shell.execute_reply\":\"2023-08-13T18:20:30.061557Z\"},\"jupyter\":{\"outputs_hidden\":false}}\ntest_df.shape\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:30.493131Z\",\"iopub.execute_input\":\"2023-08-13T18:20:30.493544Z\",\"iopub.status.idle\":\"2023-08-13T18:20:30.533053Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:30.493513Z\",\"shell.execute_reply\":\"2023-08-13T18:20:30.531929Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport torch\nfrom sklearn.metrics import accuracy_score, classification_report\n\nclassification_rep = classification_report(all_true_labels, all_predicted_labels, target_names=df['Category'].unique())\n\nprint(f\"Accuracy: {accuracy}\")\nprint(\"Classification Report:\")\nprint(classification_rep)\n\n# %% [markdown]\n# # MultinomialNB model\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:39.561389Z\",\"iopub.execute_input\":\"2023-08-13T18:20:39.562518Z\",\"iopub.status.idle\":\"2023-08-13T18:20:42.481159Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:39.562471Z\",\"shell.execute_reply\":\"2023-08-13T18:20:42.479817Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\n\n\n\n# Convert data to DataFrame\ndf = resume_df\n\n# Split the data\ntrain_df, test_df = train_test_split(df, test_size=0.01, random_state=42)\n\n# Preprocessing and feature extraction\nvectorizer = CountVectorizer(stop_words=\"english\")\nX_train = vectorizer.fit_transform(train_df[\"Resume_str\"])\nX_test = vectorizer.transform(test_df[\"Resume_str\"])\n\n# Train a model\nmodel = MultinomialNB()\nmodel.fit(X_train, train_df[\"Category\"])\n\n# Make predictions\npredictions = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(test_df[\"Category\"], predictions)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:43.439268Z\",\"iopub.execute_input\":\"2023-08-13T18:20:43.439722Z\",\"iopub.status.idle\":\"2023-08-13T18:20:43.459945Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:43.439661Z\",\"shell.execute_reply\":\"2023-08-13T18:20:43.458612Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport torch\nfrom sklearn.metrics import accuracy_score, classification_report\n\nclassification_rep = classification_report(test_df[\"Category\"], predictions)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(\"Classification Report:\")\nprint(classification_rep)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n\n\n# %% [markdown]\n# **End this endpoint, we well select MultinomialNB model is best then BERT for given dataset.**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:50.429491Z\",\"iopub.execute_input\":\"2023-08-13T18:20:50.430687Z\",\"iopub.status.idle\":\"2023-08-13T18:20:50.462739Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:50.430645Z\",\"shell.execute_reply\":\"2023-08-13T18:20:50.461421Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n#so we will chosen MultinomialNB model\n# Save the model to a file\n\nimport joblib\n\n\nmodel_filename = 'final model.pkl'\njoblib.dump(model, model_filename)\n\n\npredictions\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:52.151747Z\",\"iopub.execute_input\":\"2023-08-13T18:20:52.152204Z\",\"iopub.status.idle\":\"2023-08-13T18:20:52.166805Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:52.152164Z\",\"shell.execute_reply\":\"2023-08-13T18:20:52.165574Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n# Load the saved model from a file\nloaded_model = joblib.load(model_filename)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:54.045068Z\",\"iopub.execute_input\":\"2023-08-13T18:20:54.045499Z\",\"iopub.status.idle\":\"2023-08-13T18:20:54.052305Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:54.045465Z\",\"shell.execute_reply\":\"2023-08-13T18:20:54.051095Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nsubmission_df = test_df.iloc[:, [0,3]]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:54.958683Z\",\"iopub.execute_input\":\"2023-08-13T18:20:54.959158Z\",\"iopub.status.idle\":\"2023-08-13T18:20:54.973830Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:54.959123Z\",\"shell.execute_reply\":\"2023-08-13T18:20:54.972844Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nsubmission_df\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:55.821652Z\",\"iopub.execute_input\":\"2023-08-13T18:20:55.822570Z\",\"iopub.status.idle\":\"2023-08-13T18:20:55.829346Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:55.822526Z\",\"shell.execute_reply\":\"2023-08-13T18:20:55.828145Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nsubmission_df[\"Category\"] = predictions\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:20:58.189062Z\",\"iopub.execute_input\":\"2023-08-13T18:20:58.189487Z\",\"iopub.status.idle\":\"2023-08-13T18:20:58.202307Z\",\"shell.execute_reply.started\":\"2023-08-13T18:20:58.189452Z\",\"shell.execute_reply\":\"2023-08-13T18:20:58.201155Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nsubmission_df\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-08-13T18:21:05.843902Z\",\"iopub.execute_input\":\"2023-08-13T18:21:05.844352Z\",\"iopub.status.idle\":\"2023-08-13T18:21:05.858823Z\",\"shell.execute_reply.started\":\"2023-08-13T18:21:05.844316Z\",\"shell.execute_reply\":\"2023-08-13T18:21:05.857319Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nsubmission_df.to_csv(\"categorized_resumes.csv\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\n","metadata":{"_uuid":"db487cc5-9602-4217-b773-4c45431734df","_cell_guid":"c114c03d-c762-4272-b22b-91e901e5daea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}